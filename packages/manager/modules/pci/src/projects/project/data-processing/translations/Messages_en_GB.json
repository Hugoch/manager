{
  "data_processing_unit_gigabyte": "GB",
  "data_processing_title": "Data Processing",
  "data_processing_jobs": "Jobs",
  "data_processing_region": "Region",
  "data_processing_job_type": "Type",
  "data_processing_job_cores_ram": "vCores/RAM",
  "data_processing_job_ram": "RAM",
  "data_processing_job_creation_date": "Created",
  "data_processing_job_status": "Status",
  "data_processing_job_status_pending": "Pending",
  "data_processing_job_status_submitted": "Submitted",
  "data_processing_job_status_running": "Running",
  "data_processing_job_status_failed": "Failed",
  "data_processing_job_status_terminated": "Killed",
  "data_processing_job_status_completed": "Completed",
  "data_processing_job_status_unknown": "Unknown",
  "data_processing_create_button_label": "Submit a new job",
  "data_processing_job_name": "Name",
  "data_processing_list_button_job_details": "Job details",
  "data_processing_list_button_job_ui": "Open job user interface",
  "data_processing_list_button_job_monitoring": "Open job monitoring",
  "data_processing_list_button_job_terminate": "Kill job",
  "data_processing_details_dashboard_label": "Dashboard",
  "data_processing_details_logs_label": "Logs",
  "data_processing_details_information_label": "Information",
  "data_processing_details_information_status_label": "Status",
  "data_processing_details_information_region_label": "Region",
  "data_processing_details_information_creation_date_label": "Created",
  "data_processing_details_information_elapsed_label": "Elapsed time",
  "data_processing_details_actions_show_ui_label": "Open job user interface",
  "data_processing_details_actions_show_grafana_label": "Monitor job in Grafana",
  "data_processing_details_actions_browse_swift_label": "Browse object container",
  "data_processing_details_actions_browse_swift_unavailable_label": "Container does not exist anymore",
  "data_processing_details_actions_relaunch_label": "Duplicate and relaunch job",
  "data_processing_details_actions_save_template_label": "Save job template",
  "data_processing_details_actions_show_billing_label": "View billing console",
  "data_processing_details_actions_terminate_label": "Kill job",
  "data_processing_details_actions_label": "Actions",
  "data_processing_details_configuration_label": "Configuration",
  "data_processing_details_configuration_cores_label": "Cores (driver/workers)",
  "data_processing_details_configuration_memory_label": "Memory (driver/workers)",
  "data_processing_details_configuration_executor_count_label": "# of executors",
  "data_processing_details_configuration_swift_container_label": "Swift container",
  "data_processing_details_configuration_job_type_label": "Job type",
  "data_processing_details_configuration_jar_file_label": "JAR file",
  "data_processing_details_configuration_main_class_label": "Main class",
  "data_processing_details_configuration_arguments_label": "Arguments",
  "data_processing_details_terminate_job_title": "Kill job",
  "data_processing_details_terminate_job_description": "You are about to kill job <b>{{ jobName }}</b> ({{ jobId }}). <br />You may loose currently processed data.",
  "data_processing_details_terminate_job_delete_button": "Kill job",
  "data_processing_details_terminate_job_cancel_button": "Cancel",
  "data_processing_details_logs_title": "Logs",
  "data_processing_details_logs_swift": "You job is not running anymore. You can find your logs in your Swift Object Storage.",
  "data_processing_details_logs_swift_download_label": "Download logs",
  "data_processing_details_logs_default_message": "Waiting for logs...",
  "data_processing_submit_job_title": "Submit a job",
  "data_processing_submit_job_description": "OVH Analytics Data Compute lets you run Spark job on-demand with a customizable amount of vCPU cores and RAM.<br />Upload your code as JAR or Python files to a Swift Container, and run it using the interface below.<br />During your job execution you will get access to live logs and metrics.",
  "data_processing_submit_job_stepper_region_title": "Select a region",
  "data_processing_submit_job_stepper_job_type_title": "Select job type",
  "data_processing_submit_job_stepper_sizing_title": "Define compute and memory",
  "data_processing_submit_job_stepper_configure_title": "Configure your job",
  "data_processing_submit_job_spark_description": "Submit a Apache Spark job using either Java/Scala JAR package or Python code using Conda requirements.",
  "data_processing_submit_job_pyspark_description": "Submit a Python working directory with a Conda requirements file.",
  "data_processing_submit_job_sizing_description": "Your Spark job is ran by a driver node which distributes tasks to workers.<br />Define cores and memory allocated to your nodes and the number of workers you want to run in parallel",
  "data_processing_submit_job_button_label": "Submit job",
  "data_processing_submit_job_spinner_label": "working on it...",
  "data_processing_submit_job_error_label": "Aww snap ! An error occurred, we could not submit your job right now.",
  "data_processing_onboarding_content_1": "Data Processing is easy-to-use, cost effective and fully managed cloud service to easily run <a href=\"http://spark.apache.org/\" target=\"_blank\">Apache Spark</a> jobs.",
  "data_processing_onboarding_content_2": "With Data Processing, your job is launched in seconds and you pay per minute only for used resources. Deployment and monitoring is automated, focus on your code. You can run data processing, analytics and machine learning jobs using Java, Scala or Python with standard libraries.",
  "data_processing_onboarding_content_3": "By continuing, you allow OVH Data Processing service to access content of your object storage containers in the current project in order to run your code and save job logs.",
  "data_processing_onboarding_action_label": "Submit my first processing job",
  "data_processing_onboarding_guides_overview_title": "Overview of Data Processing",
  "data_processing_onboarding_guides_quick_start_title": "Submit your first Spark job",
  "data_processing_onboarding_guides_monitor_job_title": "Monitor your jobs",
  "data_processing_submit_job_stepper_spark_driver_template_label": "Driver template",
  "data_processing_submit_job_stepper_spark_worker_template_label": "Worker template",
  "data_processing_submit_job_stepper_spark_worker_count_label": "Worker count",
  "data_processing_submit_job_stepper_spark_worker_count_description": "Select the number of workers for your job",
  "data_processing_submit_job_stepper_spark_advanced": "Advanced configuration",
  "data_processing_submit_job_stepper_spark_standard": "Standard configuration",
  "data_processing_submit_job_stepper_spark_driver_cores_label": "Driver vCores",
  "data_processing_submit_job_stepper_spark_driver_cores_description": "",
  "data_processing_submit_job_stepper_spark_driver_memory_label": "Driver memory",
  "data_processing_submit_job_stepper_spark_driver_memory_description": "",
  "data_processing_submit_job_stepper_spark_driver_memory_overhead_label": "Driver memory overhead",
  "data_processing_submit_job_stepper_spark_driver_memory_overhead_description": "",
  "data_processing_submit_job_stepper_spark_worker_cores_label": "Worker vCores",
  "data_processing_submit_job_stepper_spark_worker_cores_description": "",
  "data_processing_submit_job_stepper_spark_worker_memory_label": "Worker memory",
  "data_processing_submit_job_stepper_spark_worker_memory_description": "Select the amount of memory per Spark worker",
  "data_processing_submit_job_stepper_spark_worker_memory_overhead_label": "Worker memory overhead",
  "data_processing_submit_job_stepper_spark_worker_memory_overhead_description": "",
  "data_processing_submit_job_stepper_spark_estimated_price": "Estimated price: ",
  "data_processing_submit_job_stepper_spark_main_class_label": "Main class",
  "data_processing_submit_job_stepper_spark_main_class_help": "eg. org.apache.spark.examples.SparkPi",
  "data_processing_submit_job_stepper_spark_jar_file_label": "Jar file",
  "data_processing_submit_job_stepper_spark_python_file_label": "Python file",
  "data_processing_submit_job_stepper_spark_jar_file_help": "Path of your JAR file inside your container",
  "data_processing_submit_job_stepper_spark_job_name_label": "Job name",
  "data_processing_submit_job_stepper_spark_job_name_help": "At least 3 characters",
  "data_processing_submit_job_stepper_spark_swift_label": "Swift container",
  "data_processing_submit_job_stepper_spark_swift_placeholder": "Select a container",
  "data_processing_submit_job_stepper_spark_version_label": "Spark version",
  "data_processing_submit_job_stepper_spark_arguments_label": "Arguments (optional)",
  "data_processing_submit_job_stepper_spark_arguments_placeholder": "Use <Return> key to add more arguments",
  "data_processing_submit_job_stepper_spark_invalid_jar_label": "This file does not seem to be a valid JAR.",
  "data_processing_submit_job_stepper_spark_not_found_file_label": "This file does not seem to exist in selected container.",
  "data_processing_submit_job_stepper_spark_jobtype_label": "Job type",
  "data_processing_submit_job_stepper_spark_jobtype_placeholder": "Select job type"
}
